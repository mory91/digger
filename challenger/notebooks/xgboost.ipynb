{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d8b71d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e18cb86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, r2_score,\n",
    "    mean_absolute_error, accuracy_score,\n",
    "    f1_score, roc_auc_score,\n",
    "    log_loss\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f45438bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 1\n",
    "MB = 1024 * 1024\n",
    "KB = 1024\n",
    "GB = 1024 * 1024 * 1024\n",
    "TIME_DELTA = 5000\n",
    "NANO_TO_MICRO = 1000\n",
    "NANO_TO_SECONDS = 1e9\n",
    "NANO_SECONDS = 1\n",
    "NROWS = 30e6\n",
    "MAX_LEN = 5\n",
    "PACKETS = \"packets\"\n",
    "SENDS = \"sends\"\n",
    "ALLOCS = \"cpu_allocations\"\n",
    "DISK_READS = \"disk_read\"\n",
    "DISK_WRITES = \"disk_write\"\n",
    "VIRTUAL_MEMORY = \"memory\"\n",
    "RSS_MEMORY = \"rss_memory\"\n",
    "DATA_MEMORY = \"data_memory\"\n",
    "S_TIME = \"s_time\"\n",
    "U_TIME = \"u_time\"\n",
    "PACKETS_1 = \"packets_1\"\n",
    "PACKETS_2 = \"packets_2\"\n",
    "PACKETS_3 = \"packets_3\"\n",
    "PACKETS_4 = \"packets_4\"\n",
    "PACKETS_5 = \"packets_5\"\n",
    "TIMES_1 = \"times_1\"\n",
    "TIMES_2 = \"times_2\"\n",
    "TIMES_3 = \"times_3\"\n",
    "START_TIME = 'start_time'\n",
    "END_TIME = 'end_time'\n",
    "SIZE = 'size'\n",
    "GAP = 'gap'\n",
    "NETWORK_IN = 'networkin'\n",
    "NETWORK_OUT = 'networkout'\n",
    "START_TIME = 'start_time'\n",
    "SRC_IP = 'src_ip'\n",
    "DEST_IP = 'dest_ip'\n",
    "SRC_PORT = 'src_port'\n",
    "DEST_PORT = 'dest_port'\n",
    "\n",
    "NSDI_FEATURES = [DISK_READS, DISK_WRITES, VIRTUAL_MEMORY, S_TIME,\n",
    "                 START_TIME, END_TIME, GAP, NETWORK_IN, SIZE,\n",
    "                 NETWORK_OUT]  # SRC_IP, DEST_IP, SRC_PORT, DEST_PORT]\n",
    "ALL_FEATURES = NSDI_FEATURES + [ALLOCS, RSS_MEMORY, DATA_MEMORY, U_TIME, SRC_IP, DEST_IP, SRC_PORT, DEST_PORT]\n",
    "FS_FEATURES = [SIZE, GAP, DISK_WRITES]\n",
    "FULL_PATH = \"../files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e2d1dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scaling(training_path):\n",
    "    scaling = {}\n",
    "    df = pd.read_csv(training_path, index_col=False)\n",
    "    for column in df.columns:\n",
    "        scaling[column] = float(df[column].max())\n",
    "    return scaling\n",
    "\n",
    "def prepare_files(file, window_size, scaling, target_column='size'):\n",
    "    df = pd.read_csv(file, index_col=False)\n",
    "    if scaling is not None:\n",
    "        df = df.apply((lambda x: resize(x, scaling)), axis=0)\n",
    "    flow_size = df[target_column]\n",
    "    df[target_column] = flow_size\n",
    "    # extend the window\n",
    "    final_df = df.copy()\n",
    "    for sample_num in range(1, window_size):\n",
    "        shifted = df.shift(sample_num)\n",
    "        shifted.columns = map(lambda x: x+str(sample_num), shifted.columns)\n",
    "        final_df = pd.concat([shifted, final_df], axis=1)\n",
    "\n",
    "    final_df = final_df.fillna(0)\n",
    "    final_df = final_df.drop(target_column, axis=1)\n",
    "\n",
    "    return (final_df, flow_size)\n",
    "\n",
    "def make_io(f_df, f_size):\n",
    "    inputs = None\n",
    "    outputs = None\n",
    "    i_data = f_df.values\n",
    "    o_data = f_size.tolist()\n",
    "    if inputs is None:\n",
    "        inputs = i_data\n",
    "        outputs = o_data\n",
    "    else:\n",
    "        inputs = np.append(inputs, i_data, axis=0)\n",
    "        outputs = np.append(outputs, o_data)\n",
    "    return (inputs, outputs)\n",
    "\n",
    "def resize(s, scaling):\n",
    "    return (s / scaling[s.name])\n",
    "\n",
    "def print_metrics(real, prediction):\n",
    "    mse = mean_squared_error(real, prediction)\n",
    "    mae = mean_absolute_error(real, prediction)\n",
    "    r2 = r2_score(real, prediction)\n",
    "    scores = {'mse': mse, 'mae': mae, 'r2': r2}\n",
    "    return scores\n",
    "\n",
    "def print_performance(file, model, scaling):\n",
    "    df, flow_size = prepare_files(\n",
    "        file,\n",
    "        WINDOW_SIZE,\n",
    "        scaling,\n",
    "        'size'\n",
    "    )\n",
    "    inputs, outputs = make_io(df, flow_size)\n",
    "    y_pred = model.predict(\n",
    "        xgb.DMatrix(inputs, feature_names=df.columns)\n",
    "    )\n",
    "    pred = y_pred.tolist()\n",
    "\n",
    "    return print_metrics(\n",
    "        outputs, pred\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8057cd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = 500\n",
    "flows_df = pd.read_csv(f\"{FULL_PATH}/{td}/full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6661168",
   "metadata": {},
   "outputs": [],
   "source": [
    "flows_df  = flows_df[flows_df['gap'] >= 0]\n",
    "flows_df = flows_df[:6000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d901b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_path = 'tmp-data'\n",
    "target_file_name = \"flows.csv\"\n",
    "tmp_train_path = f\"{tmp_path}/train\"\n",
    "tmp_test_path = f\"{tmp_path}/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1275bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "flows_train, flows_test = train_test_split(\n",
    "    flows_df, shuffle=False, test_size=0.3\n",
    ")\n",
    "flows_train.to_csv(\n",
    "    f\"{tmp_train_path}/{target_file_name}\",\n",
    "    index=False\n",
    ")\n",
    "flows_test.to_csv(\n",
    "    f\"{tmp_test_path}/{target_file_name}\",\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62b68f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path =  f\"{tmp_train_path}/flows.csv\"\n",
    "test_path =  f\"{tmp_test_path}/flows.csv\"\n",
    "scaling = calculate_scaling(training_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3114e3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 5\n",
    "\n",
    "df, flow_size = prepare_files(\n",
    "    training_path,\n",
    "    WINDOW_SIZE,\n",
    "    scaling,\n",
    "    'size'\n",
    ")\n",
    "\n",
    "inputs, outputs = make_io(df, flow_size)\n",
    "\n",
    "# fit model no training data\n",
    "number_of_trees = 20\n",
    "param = {\n",
    "    'max_depth': 12,\n",
    "    'booster': 'gbtree',\n",
    "    \"predictor\": \"gpu_predictor\",\n",
    "    'tree_method': 'gpu_hist',\n",
    "    'colsample_bytree': 0.7,\n",
    "}\n",
    "extra_params = dict()\n",
    "extra_params.update(\n",
    "    objective='reg:squarederror',\n",
    "    eval_metric='mae'\n",
    ")\n",
    "\n",
    "param.update(extra_params)\n",
    "training = xgb.DMatrix(inputs, outputs, feature_names=df.columns)\n",
    "model = xgb.train(param, training, number_of_trees)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf0f7d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'mse': 0.0010277209106226437,\n",
       "  'mae': 0.012392375580179377,\n",
       "  'r2': 0.46641987672979357},\n",
       " 'test': {'mse': 0.0015914562328401773,\n",
       "  'mae': 0.017461205469279494,\n",
       "  'r2': 0.19677862794596923}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = {}\n",
    "result['train'] = print_performance(\n",
    "    training_path, model, scaling\n",
    ")\n",
    "result['test'] = print_performance(\n",
    "    test_path, model, scaling\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc37b51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
