{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.functional import F\n",
    "from torch import nn\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from trace_process import *\n",
    "\n",
    "TIME_DELTA = 1000 * NANO_TO_MICRO\n",
    "SEQ_L = 200\n",
    "N_EPOCHS = 10\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_recored = 3555634102\n",
    "skip = 0\n",
    "chunk = 10000000\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"../data/1/node-1/packets\", \n",
    "    sep='\\t', \n",
    "    lineterminator='\\n', \n",
    "    header=None,\n",
    "    index_col=False,\n",
    "    names=['timestamp', 'size', 'src', 'dest', 'dir'], \n",
    "    dtype={'size': \"int16\", 'src': \"category\", 'dest': \"category\", \"timestamp\": \"int64\", \"size\": \"int16\", \"dir\": \"int8\"},\n",
    "    skiprows=skip,\n",
    "    nrows=chunk\n",
    ")\n",
    "df = df[df['dir'] == 2][[\"timestamp\", \"size\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = df.values\n",
    "flows_indexes, flow_sizes = get_flows_index(trace, TIME_DELTA)\n",
    "start = np.argwhere(flows_indexes[:, 0] > SEQ_L).min()\n",
    "packets = trace[:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EM_THRESHOLD = np.median(flow_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TraceDataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, packet_trace, flows_indexes, flow_sizes, start):\n",
    "        self.packet_trace = packet_trace\n",
    "        self.flows_indexes = flows_indexes\n",
    "        self.flow_sizes = flow_sizes\n",
    "        self.start = start\n",
    "    \n",
    "    def __iter__(self):\n",
    "        idx = start\n",
    "        end = len(self.flows_indexes[start:, 0])\n",
    "        while idx < end - 1:\n",
    "            target = self.flows_indexes[idx, 0]\n",
    "            x = self.packet_trace[target - SEQ_L:target]\n",
    "            y = (self.flow_sizes[idx + 1] > EM_THRESHOLD) * 1.\n",
    "            yield x[None, :].astype(np.float32), y\n",
    "            idx += 1\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.flows_indexes) - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, filters=(4, 3, 2, 1)):\n",
    "        super().__init__()\n",
    "        self.filters = filters\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, filters[0], (1, 2))\n",
    "        self.bn1 = nn.BatchNorm2d(filters[0])\n",
    "        self.conv2 = nn.Conv2d(filters[0], filters[1], (5, 1))\n",
    "        self.bn2 = nn.BatchNorm2d(filters[1])\n",
    "        self.conv3 = nn.Conv2d(filters[1], filters[2], (4, 1))\n",
    "        self.bn3 = nn.BatchNorm2d(filters[2])\n",
    "        self.conv4 = nn.Conv2d(filters[2], filters[3], (3, 1))\n",
    "        self.bn4 = nn.BatchNorm2d(filters[3])\n",
    "        self.linear = nn.Linear(filters[3] * 10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.avg_pool2d(x, (2, 1))\n",
    "        x = self.bn1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.avg_pool2d(x, (2, 1))\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.avg_pool2d(x, (2, 1))\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.avg_pool2d(x, (2, 1))\n",
    "        x = self.bn4(x)\n",
    "        \n",
    "        x = x.view(-1, self.filters[-1] * 10)\n",
    "\n",
    "        x = self.linear(x)\n",
    "        x = F.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TraceDataset(packets, flows_indexes, flow_sizes, start)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "model = CNNModel()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 1e-5, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "  model = model.cuda()\n",
    "  criterion = criterion.cuda()\n",
    "  device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "  device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_and_correct(model, batch, criterion, device):\n",
    "    data, target = batch\n",
    "    data, target = data.to(device, dtype=torch.float), target.to(device, dtype=torch.float)\n",
    "    output = model(data)\n",
    "    output = torch.squeeze(output)\n",
    "    \n",
    "    loss = criterion(output, target)\n",
    "\n",
    "    pred = torch.round(output).int()\n",
    "    target_int = target.int()\n",
    "\n",
    "    true_num = pred.eq(target_int.data.view_as(pred)).sum()\n",
    "\n",
    "    return loss, true_num\n",
    "\n",
    "def step(loss, optimizer):\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb9c4c4a11ba4b11b7129538ff2bb668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f41cb02a98844960869e19f3ad6a19fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21824 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d673d45808bb49bbb24e7966c41b1514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21824 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fbca09f86544d4db9faaccc4f256957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21824 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b8f15f7bddb4545b7976eb08858bde5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21824 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "578c9a7d7ed84f58a34233f44c9e6945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21824 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c701601d15774d688249420d596fea7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21824 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8baf0feab2fd456b822faae51f8ba1e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21824 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb9d9157773452d8cfb5ea0ca5ff212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21824 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2b42c13d05149b2b8169e65a27f3cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21824 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c50153abe5024feebfc6df317170daa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21824 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "pbar = tqdm(range(N_EPOCHS))\n",
    "\n",
    "for i in pbar:\n",
    "  total_train_loss = 0.0\n",
    "  total_train_correct = 0.0\n",
    "\n",
    "  model.train()\n",
    "\n",
    "  for batch in tqdm(train_dataloader, leave=False):\n",
    "    loss, correct = get_loss_and_correct(model, batch, criterion, device)\n",
    "    step(loss, optimizer)\n",
    "    total_train_loss += loss.item()\n",
    "    total_train_correct += correct.item()\n",
    "\n",
    "  mean_train_loss = total_train_loss / len(train_dataset)\n",
    "  train_accuracy = total_train_correct / len(train_dataset)\n",
    "\n",
    "  train_losses.append(mean_train_loss)\n",
    "\n",
    "  train_accuracies.append(train_accuracy)\n",
    "\n",
    "  pbar.set_postfix({'train_loss': mean_train_loss, 'train_accuracy': train_accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6090771627565983"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.argwhere(flow_sizes <= EM_THRESHOLD)) / len(flow_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2e27e19ca6a05df96a2b941e6f80a39c60cf0d4b0a98b67408d6945db8a91ff3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 ('torch-test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
