{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from trace_process import *\n",
    "\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_out_path = f\"{DEFAULT_PREFIX}/{TEST_PATH}/{NETWORK_OUT}\"\n",
    "memory_path = f\"{DEFAULT_PREFIX}/{TEST_PATH}/{MEMORY}\"\n",
    "network_out_raw_path = f\"../{network_out_path}\"\n",
    "memory_raw_path = f\"../{memory_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_delta = 100 * NANO_TO_MICRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = build_array(memory_raw_path, limit=2)\n",
    "network_out_np = build_array(network_out_raw_path, limit=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "packets_df = save_as_pd(network_out_np, ['time', 'packet_size'], f\"{DEFAULT_PREFIX}/{TEST_PATH}/{NETWORK_OUT}.csv\")\n",
    "memory_df = save_as_pd(memory, ['time', 'memory'], f\"{DEFAULT_PREFIX}/{TEST_PATH}/{MEMORY}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_times, flow_sizes = get_flow(network_out_np, time_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "flows_df = pd.DataFrame({\"s\": flow_times[:,0], \"e\": flow_times[:,1], \"size\": flow_sizes})\n",
    "flows_df.to_csv(f\"{DEFAULT_PREFIX}/{TEST_PATH}/flows.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_normalized = normalize(memory, axis=0, norm='max')\n",
    "network_out_np_normalized = normalize(network_out_np, axis=0, norm='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_trace_packet, flow_sizes = get_flow_trace(network_out_np, time_delta, network_out_np_normalized)\n",
    "# flow_trace_packet, flow_sizes = get_flow_trace(network_out_np, 500, network_out_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_sizes = flow_sizes / max(flow_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flow_times' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/morteza/code/digger/morteza/xgboost.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/morteza/code/digger/morteza/xgboost.ipynb#ch0000010?line=0'>1</a>\u001b[0m memory_of_flows \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msearchsorted(memory[:,\u001b[39m0\u001b[39m], flow_times)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'flow_times' is not defined"
     ]
    }
   ],
   "source": [
    "memory_of_flows = np.searchsorted(memory[:,0], flow_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_memory = [np.sum(memory_normalized[f[0]:f[1] + 1,0]) / (1 + f[1] - f[0]) for f in memory_of_flows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "EM_THRESHOLD = np.median(flow_sizes)\n",
    "MAX_LEN = max([len(f) for f in flow_trace_packet])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "446"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_flows = np.array([np.pad(f, (MAX_LEN - len(f), 0), 'constant') for f in flow_trace_packet])\n",
    "flows_size_classes = (flow_sizes > EM_THRESHOLD) * 1.\n",
    "flow_size_classes = np.roll(flows_size_classes, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['p' + str(i) for i in range(9)] + ['m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = np.c_[padded_flows, all_memory] # TO ADD MEMORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dd, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test, labels_train, labels_test = train_test_split(df, flow_size_classes, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_x = torch.Tensor(data_train.values) \n",
    "tensor_y = torch.Tensor(labels_train)\n",
    "\n",
    "train_dataset = TensorDataset(tensor_x[:,None,], tensor_y) \n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.functional import F\n",
    "\n",
    "class CNN2Model(nn.Module):\n",
    "    def __init__(self, filters=(8, 4, 2)):\n",
    "        super().__init__()\n",
    "        self.filters = filters\n",
    "\n",
    "        self.conv1 = nn.Conv1d(1, filters[0], 2)\n",
    "        self.bn1 = nn.BatchNorm1d(filters[0])\n",
    "        self.linear = nn.Linear(filters[0] * 4, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool1d(x, 2)\n",
    "        x = self.bn1(x)\n",
    "\n",
    "        x = x.view(-1, self.filters[0] * 4)\n",
    "\n",
    "        x = self.linear(x)\n",
    "        x = F.sigmoid(x)\n",
    "\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38004f065b4a4858ba81d47050d79b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81187e9401e7485391a322650273bec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/615262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8e4c9001144e18adb23fcaae2472ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/615262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d88034722b476f9506bcf46c6469d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/615262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/morteza/code/digger/morteza/xgboost.ipynb Cell 21'\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/morteza/code/digger/morteza/xgboost.ipynb#ch0000020?line=41'>42</a>\u001b[0m total_train_correct \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/morteza/code/digger/morteza/xgboost.ipynb#ch0000020?line=43'>44</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/morteza/code/digger/morteza/xgboost.ipynb#ch0000020?line=45'>46</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m tqdm(train_dataloader, leave\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/morteza/code/digger/morteza/xgboost.ipynb#ch0000020?line=46'>47</a>\u001b[0m   loss, correct \u001b[39m=\u001b[39m get_loss_and_correct(model, batch, criterion, device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/morteza/code/digger/morteza/xgboost.ipynb#ch0000020?line=47'>48</a>\u001b[0m   step(loss, optimizer)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-test/lib/python3.9/site-packages/tqdm/notebook.py:258\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/tqdm/notebook.py?line=255'>256</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/tqdm/notebook.py?line=256'>257</a>\u001b[0m     it \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m(tqdm_notebook, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__iter__\u001b[39m()\n\u001b[0;32m--> <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/tqdm/notebook.py?line=257'>258</a>\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m it:\n\u001b[1;32m    <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/tqdm/notebook.py?line=258'>259</a>\u001b[0m         \u001b[39m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/tqdm/notebook.py?line=259'>260</a>\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m    <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/tqdm/notebook.py?line=260'>261</a>\u001b[0m \u001b[39m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-test/lib/python3.9/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/tqdm/std.py?line=1191'>1192</a>\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/tqdm/std.py?line=1193'>1194</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/tqdm/std.py?line=1194'>1195</a>\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/tqdm/std.py?line=1195'>1196</a>\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/tqdm/std.py?line=1196'>1197</a>\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/tqdm/std.py?line=1197'>1198</a>\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-test/lib/python3.9/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=527'>528</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=528'>529</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=529'>530</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=530'>531</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=531'>532</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=532'>533</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=533'>534</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-test/lib/python3.9/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=567'>568</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=568'>569</a>\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=569'>570</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=570'>571</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/torch/utils/data/dataloader.py?line=571'>572</a>\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-test/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-test/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-test/lib/python3.9/site-packages/torch/utils/data/dataset.py:369\u001b[0m, in \u001b[0;36mTensorDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/torch/utils/data/dataset.py?line=367'>368</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, index):\n\u001b[0;32m--> <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/torch/utils/data/dataset.py?line=368'>369</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39;49m(tensor[index] \u001b[39mfor\u001b[39;49;00m tensor \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtensors)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch-test/lib/python3.9/site-packages/torch/utils/data/dataset.py:369\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/torch/utils/data/dataset.py?line=367'>368</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, index):\n\u001b[0;32m--> <a href='file:///home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/torch/utils/data/dataset.py?line=368'>369</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(tensor[index] \u001b[39mfor\u001b[39;00m tensor \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtensors)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "model = CNN2Model()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.005, momentum=0.5)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "def get_loss_and_correct(model, batch, criterion, device):\n",
    "    data, target = batch\n",
    "    data, target = data.to(device, dtype=torch.float), target.to(device, dtype=torch.float)\n",
    "    output = model(data)\n",
    "    output = torch.squeeze(output)\n",
    "\n",
    "    loss = criterion(output, target)\n",
    "\n",
    "    pred = torch.round(output)\n",
    "    true_num = pred.eq(target.data.view_as(pred)).sum()\n",
    "\n",
    "    return loss, true_num\n",
    "\n",
    "def step(loss, optimizer):\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "pbar = tqdm(range(N_EPOCHS))\n",
    "\n",
    "for i in pbar:\n",
    "  total_train_loss = 0.0\n",
    "  total_train_correct = 0.0\n",
    "\n",
    "  model.train()\n",
    "\n",
    "  for batch in tqdm(train_dataloader, leave=False):\n",
    "    loss, correct = get_loss_and_correct(model, batch, criterion, device)\n",
    "    step(loss, optimizer)\n",
    "    total_train_loss += loss.item()\n",
    "    total_train_correct += correct.item()\n",
    "\n",
    "  mean_train_loss = total_train_loss / len(train_dataset)\n",
    "  train_accuracy = total_train_correct / len(train_dataset)\n",
    "\n",
    "  train_losses.append(mean_train_loss)\n",
    "\n",
    "  train_accuracies.append(train_accuracy)\n",
    "\n",
    "  pbar.set_postfix({'train_loss': mean_train_loss, 'train_accuracy': train_accuracy})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dtest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/morteza/code/digger/morteza/xgboost.ipynb Cell 22'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/morteza/code/digger/morteza/xgboost.ipynb#ch0000022?line=0'>1</a>\u001b[0m param \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39meta\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0.05\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mbinary:logistic\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpredictor\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mgpu_predictor\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m10\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtree_method\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mgpu_hist\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39meval_metric\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39merror\u001b[39m\u001b[39m'\u001b[39m}\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/morteza/code/digger/morteza/xgboost.ipynb#ch0000022?line=1'>2</a>\u001b[0m evallist \u001b[39m=\u001b[39m [(dtest, \u001b[39m'\u001b[39m\u001b[39meval\u001b[39m\u001b[39m'\u001b[39m), (dtrain, \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dtest' is not defined"
     ]
    }
   ],
   "source": [
    "param = {'eta': 0.05, 'objective': 'binary:logistic', 'predictor': 'gpu_predictor', 'max_depth': 10, 'tree_method': 'gpu_hist', 'eval_metric': 'error'}\n",
    "evallist = [(dtest, 'eval'), (dtrain, 'train')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              eta=0.05, eval_metric='error', gamma=0, gpu_id=0,\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.0500000007, max_delta_step=0, max_depth=10,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=24, num_parallel_tree=1,\n",
       "              predictor='gpu_predictor', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='gpu_hist', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier(**param)\n",
    "model.fit(data_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score:  0.7051902813304949\n",
      "train score:  0.7052437138790638\n"
     ]
    }
   ],
   "source": [
    "print('test score: ', np.sum((model.predict(data_test) == labels_test) * 1) / len(labels_test))\n",
    "print('train score: ', np.sum((model.predict(data_train) == labels_train) * 1) / len(labels_train))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2e27e19ca6a05df96a2b941e6f80a39c60cf0d4b0a98b67408d6945db8a91ff3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
