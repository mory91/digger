{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from trace_process import *\n",
    "\n",
    "TIME_DELTA = 5000 * NANO_TO_MICRO\n",
    "BATCH_SIZE = 32\n",
    "MTU = 1514\n",
    "WINDOW_SIZE = 10\n",
    "\n",
    "file_name = \"../data/13/node-2/train/packets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_115072/334754765.py:1: DtypeWarning: Columns (0,1,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    file_name, \n",
    "    sep='\\t', \n",
    "    lineterminator='\\n', \n",
    "    header=None,\n",
    "    index_col=False,\n",
    "    names=['timestamp', 'size', 'src', 'dest', 'dir'], \n",
    "    dtype={'src': \"category\", 'dest': \"category\"},\n",
    "    on_bad_lines='skip',\n",
    "    keep_default_na=False,\n",
    ").dropna()\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "df = df.dropna()\n",
    "df = df[df['dir'] == 1][[\"timestamp\", \"size\"]]\n",
    "df = df.sort_values(by='timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/morteza/code/digger/morteza/trace_process.py:96: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  flows_packets = np.array([value_trace[slice(*f)] for f in flows])\n",
      "/home/morteza/code/digger/morteza/trace_process.py:97: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  flow_times = np.array([time_stamp[slice(*f)] for f in flows])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of flows:  56758\n",
      "EM:  214356.0\n"
     ]
    }
   ],
   "source": [
    "trace = df.values\n",
    "flow_packets, flow_times, flow_sizes, flows_span = get_flow_trace_time(trace, TIME_DELTA)\n",
    "EM = np.median(flow_sizes)\n",
    "print(\"Number of flows: \", len(flow_sizes))\n",
    "print(\"EM: \", EM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((flow_sizes > EM) * 1) / len(flow_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading mem file\n",
    "\n",
    "#mem_df = pd.read_csv(\n",
    "#    \"../data/3/node-1/train/allocations\", \n",
    "#    sep='\\t', \n",
    "#    lineterminator='\\n', \n",
    "#    header=None,\n",
    "#    index_col=False,\n",
    "#    names=['timestamp', 'size'], \n",
    "#    dtype={\"size\": \"float64\"}\n",
    "#)\n",
    "#\n",
    "#mem_trace = mem_df.values\n",
    "#\n",
    "#tmp_mem = mem_trace[:, 1].reshape(-1, 1)\n",
    "#tmp_mem = preprocessing.MinMaxScaler().fit_transform(tmp_mem)\n",
    "#mem_trace[:, 1] = tmp_mem.reshape(-1)\n",
    "\n",
    "# Aligning Mem and Flows\n",
    "\n",
    "#starts = np.searchsorted(mem_trace[:, 0], flows_span[:, 0])\n",
    "#ends = np.searchsorted(mem_trace[:, 0], flows_span[:, 1])\n",
    "#flows_mem_idx = np.column_stack((starts, ends))\n",
    "#flows_mem_trace = np.array([mem_trace[:, 1][slice(*f)] for f in flows_mem_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 20_000\n",
    "TEST_SIZE = 5_000\n",
    "\n",
    "indexes = list(range(5, len(flow_sizes) - 1))\n",
    "random.shuffle(indexes)\n",
    "train_indexes = indexes[:TRAIN_SIZE]\n",
    "test_indexes = indexes[TRAIN_SIZE:TRAIN_SIZE + TEST_SIZE]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def session_2d_histogram(ts, sizes, path, plot=False):\n",
    "    if len(ts) == 1:\n",
    "        ts_norm = np.array([0.0])\n",
    "    else:\n",
    "        ts_norm = ((np.array(ts) - ts[0]) / (ts[-1] - ts[0])) * MTU\n",
    "    H, xedges, yedges = np.histogram2d(sizes, ts_norm, bins=(range(0, MTU + 1, 1), range(0, MTU + 1, 1)))\n",
    "\n",
    "    if plot:\n",
    "        plt.set_cmap('plasma')\n",
    "        plt.pcolormesh(xedges, yedges, H)\n",
    "        plt.xlim(0, MTU + 1)\n",
    "        plt.ylim(0, MTU + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.savefig(path)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EM = np.median(flow_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch.functional import F\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import multiprocessing\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "import random\n",
    "\n",
    "NUM_PROCESS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TraceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, flow_times, flow_packets, flow_sizes, indexes, em):\n",
    "        self.flow_times = flow_times\n",
    "        self.flow_packets = flow_packets\n",
    "        self.flow_sizes = flow_sizes\n",
    "        self.indexes = indexes\n",
    "        self.em = em\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        idx = self.indexes[index]\n",
    "        y = 1 if self.flow_sizes[idx + 1] > self.em else 0\n",
    "        x = torch.Tensor(np.array([session_2d_histogram(self.flow_times[idx - i], self.flow_packets[idx - i], '', False) for i in range(WINDOW_SIZE)]))\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TraceDataset(flow_times, flow_packets, flow_sizes, train_indexes, EM)\n",
    "test_dataset = TraceDataset(flow_times, flow_packets, flow_sizes, test_indexes, EM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=5)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, filters=(10, 20)):\n",
    "        super().__init__()\n",
    "        self.filters = filters\n",
    "\n",
    "        self.conv1 = nn.Conv2d(WINDOW_SIZE, out_channels=self.filters[0], kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(filters[0])\n",
    "        self.conv2 = nn.Conv2d(filters[0], out_channels=filters[1], kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(filters[1])\n",
    "        self.d2 = nn.Dropout(p=0.25)\n",
    "        self.linear1 = nn.Linear(filters[1] * 93 * 93, 64)\n",
    "        self.d3 = nn.Dropout(p=0.5)\n",
    "        self.linear2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.bn1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        x = self.d2(x)\n",
    "\n",
    "        x = x.view(-1, self.filters[-1] * 93 * 93)\n",
    "\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.d3(x)\n",
    "\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        x = F.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5131892009504be2a2b2f7775c2c2416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9672b91a34c441a4a399ee209e4119e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/morteza/anaconda3/envs/torch-test/lib/python3.9/site-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.66045\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f8130de5344721b5f28950488d99e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7054\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b79e3241c1394b35a818ac4d63e356d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.71355\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "242d8d3451ce4898ad3a377ecf94b587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "model = CNNModel()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.003, momentum=0.5)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "def get_loss_and_correct(model, batch, criterion, device):\n",
    "    img, target = batch\n",
    "    img, target = img.to(device, dtype=torch.float), target.to(device, dtype=torch.float)\n",
    "    output = model(img)\n",
    "    output = torch.squeeze(output)\n",
    "\n",
    "    loss = criterion(output, target)\n",
    "\n",
    "    pred = torch.round(output).int()\n",
    "    true_num = pred.eq(target.int().data.view_as(pred)).sum()\n",
    "\n",
    "    return loss, true_num\n",
    "\n",
    "def step(loss, optimizer):\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "pbar = tqdm(range(N_EPOCHS))\n",
    "\n",
    "for i in pbar:\n",
    "  total_train_loss = 0.0\n",
    "  total_train_correct = 0.0\n",
    "\n",
    "  model.train()\n",
    "\n",
    "  for batch in tqdm(train_dataloader, leave=False):\n",
    "    loss, correct = get_loss_and_correct(model, batch, criterion, device)\n",
    "    step(loss, optimizer)\n",
    "    total_train_loss += loss.item()\n",
    "    total_train_correct += correct.item()\n",
    "\n",
    "  mean_train_loss = total_train_loss / len(train_dataset)\n",
    "  train_accuracy = total_train_correct / len(train_dataset)\n",
    "\n",
    "  train_losses.append(mean_train_loss)\n",
    "\n",
    "  train_accuracies.append(train_accuracy)\n",
    "\n",
    "  pbar.set_postfix({'train_loss': mean_train_loss, 'train_accuracy': train_accuracy})\n",
    "  print(train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pt\")\n",
    "\n",
    "cpu = torch.device('cpu')\n",
    "cpu_model = CNNModel()\n",
    "cpu_model.load_state_dict(torch.load(\"model.pt\", map_location=cpu))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b26de851fec24956b842333ea01c351a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  tensor(0.6672)\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "for batch in tqdm(test_dataloader, leave=False):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        img, target = batch\n",
    "        img, target = img.float(), target.float()\n",
    "        # data, target = data.to(device, dtype=torch.float), target.to(device, dtype=torch.float)\n",
    "        output = cpu_model(img)\n",
    "        output = torch.squeeze(output)\n",
    "        pred = torch.round(output).int()\n",
    "        true_num = pred.eq(target.data.view_as(pred)).sum()\n",
    "        correct += true_num\n",
    "        total += len(img)\n",
    "    \n",
    "print(\"Test Accuracy: \", correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAADrCAYAAABXYUzjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAADjUlEQVR4nO3YMU4CQBBA0V1iYkFFQWLnGfRcHsBDwiGo8Q5rTywkAX+C75U7U0z1i51rrQHA39vUBwD8VwIMEBFggIgAA0QEGCAiwACRp2uW59yuzdzd6xaAh/P2/jKOx+PXWmt/ObsqwJu5G9vnj9tdBvDgDofPMec8/TTzBQEQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBkrrV+vzzneYxxut85AA/pda21v3y8KsAA3I4vCICIAANEBBggIsAAEQEGiAgwQESAASICDBARYIDINz3gG1WYGUAgAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for idx in train_indexes[:20]:\n",
    "    c = 'E' if flow_sizes[idx + 1] > EM else 'M'\n",
    "    session_2d_histogram(flow_times[idx], flow_packets[idx], f'./flowpics/{c}/{idx}', True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2e27e19ca6a05df96a2b941e6f80a39c60cf0d4b0a98b67408d6945db8a91ff3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
